{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bb1の付け根はC5でキャッピング\n",
    "- bb1のbb23側はフルオレンでキャっピング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def is_kaggle_kernel():\n",
    "    return os.path.exists('/kaggle/working')\n",
    "\n",
    "if is_kaggle_kernel():\n",
    "\n",
    "    BASE_DIR = Path(\"/kaggle\")\n",
    "    DATA_DIR = BASE_DIR / \"input\"\n",
    "    OUTPUT_DIR = BASE_DIR / \"working\"\n",
    "    print('on kaggle notebook')\n",
    "\n",
    "else:\n",
    "    BASE_DIR = Path(os.getcwd()) / './../'\n",
    "    DATA_DIR = BASE_DIR / \"data\"\n",
    "    OUTPUT_DIR = BASE_DIR / \"output/eda\"\n",
    "    \n",
    "class paths:    \n",
    "    DATA_DIR = DATA_DIR\n",
    "    \n",
    "    # TEST_PATH = DATA_DIR / \"test.parquet\"\n",
    "    OUTPUT_DIR = OUTPUT_DIR\n",
    "    SHRUNKEN_DATA_DIR = DATA_DIR / \"shrunken-data\"\n",
    "    \n",
    "    TRAIN_PATH_ORIG = DATA_DIR / \"shrunken-train-set/train.parquet\"\n",
    "    TEST_PATH_ORIG = DATA_DIR / \"shrunken-train-set/test.parquet\"\n",
    "    \n",
    "    TRAIN_PATH = SHRUNKEN_DATA_DIR / \"train.parquet\"\n",
    "    TEST_PATH = SHRUNKEN_DATA_DIR / \"test.parquet\"\n",
    "    SUB_PATH = SHRUNKEN_DATA_DIR / \"sub.parquet\"\n",
    "    \n",
    "    OUTPUT_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "# import duckdb\n",
    "# import lightgbm as lgb\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "import pickle\n",
    "from funcs.chemical_func import combine_fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m df_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(paths\u001b[38;5;241m.\u001b[39mTRAIN_PATH, columns\u001b[38;5;241m=\u001b[39mbb_cols \u001b[38;5;241m+\u001b[39m TARGETS)\n\u001b[1;32m      8\u001b[0m df_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(paths\u001b[38;5;241m.\u001b[39mTEST_PATH, columns\u001b[38;5;241m=\u001b[39mbb_cols)\n\u001b[0;32m---> 10\u001b[0m df_train_orig \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN_PATH_ORIG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmolecule_smiles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m df_test_orig \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(paths\u001b[38;5;241m.\u001b[39mTEST_PATH_ORIG, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmolecule_smiles\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(paths\u001b[38;5;241m.\u001b[39mSHRUNKEN_DATA_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbb1_smiles2idx.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py:503\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03mLoad a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;124;03mDataFrame\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    501\u001b[0m impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py:251\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m path_or_handle, handles, kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    245\u001b[0m     path,\n\u001b[1;32m    246\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    247\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    248\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    249\u001b[0m )\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    255\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m_as_manager(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/parquet/core.py:2871\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size, partitioning, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[1;32m   2860\u001b[0m         \u001b[38;5;66;03m# TODO test that source is not a directory or a list\u001b[39;00m\n\u001b[1;32m   2861\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m ParquetFile(\n\u001b[1;32m   2862\u001b[0m             source, metadata\u001b[38;5;241m=\u001b[39mmetadata, read_dictionary\u001b[38;5;241m=\u001b[39mread_dictionary,\n\u001b[1;32m   2863\u001b[0m             memory_map\u001b[38;5;241m=\u001b[39mmemory_map, buffer_size\u001b[38;5;241m=\u001b[39mbuffer_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2868\u001b[0m             thrift_container_size_limit\u001b[38;5;241m=\u001b[39mthrift_container_size_limit,\n\u001b[1;32m   2869\u001b[0m         )\n\u001b[0;32m-> 2871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2872\u001b[0m \u001b[43m                        \u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2874\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2875\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_legacy_dataset=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to get the legacy behaviour is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2876\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated as of pyarrow 8.0.0, and the legacy implementation will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2877\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe removed in a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2878\u001b[0m     \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   2880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_prefixes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/parquet/core.py:2517\u001b[0m, in \u001b[0;36m_ParquetDatasetV2.read\u001b[0;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[1;32m   2509\u001b[0m         index_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   2510\u001b[0m             col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m _get_pandas_index_columns(metadata)\n\u001b[1;32m   2511\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m   2512\u001b[0m         ]\n\u001b[1;32m   2513\u001b[0m         columns \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2514\u001b[0m             \u001b[38;5;28mlist\u001b[39m(columns) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(index_columns) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(columns))\n\u001b[1;32m   2515\u001b[0m         )\n\u001b[0;32m-> 2517\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter_expression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\n\u001b[1;32m   2520\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;66;03m# if use_pandas_metadata, restore the pandas metadata (which gets\u001b[39;00m\n\u001b[1;32m   2523\u001b[0m \u001b[38;5;66;03m# lost if doing a specific `columns` selection in to_table)\u001b[39;00m\n\u001b[1;32m   2524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pandas_metadata:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bb_cols = ['buildingblock1_smiles', 'buildingblock2_smiles','buildingblock3_smiles', \n",
    "           'buildingblock1_smiles_scaffold', \"buildingblock2_smiles_scaffold\", \"buildingblock3_smiles_scaffold\",\n",
    "    ]\n",
    "\n",
    "TARGETS = ['binds_BRD4', 'binds_HSA','binds_sEH']\n",
    "\n",
    "df_train = pd.read_parquet(paths.TRAIN_PATH, columns=bb_cols + TARGETS)\n",
    "df_test = pd.read_parquet(paths.TEST_PATH, columns=bb_cols)\n",
    "\n",
    "df_train_orig = pd.read_parquet(paths.TRAIN_PATH_ORIG, columns=[\"molecule_smiles\"])\n",
    "df_test_orig = pd.read_parquet(paths.TEST_PATH_ORIG, columns=[\"molecule_smiles\"])\n",
    "\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'bb1_smiles2idx.pickle', 'rb') as file:\n",
    "    bb1_smiles2idx = pickle.load(file)\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'bb23_smiles2idx.pickle', 'rb') as file:\n",
    "    bb23_smiles2idx = pickle.load(file)\n",
    "    \n",
    "bb1_idx2smiles = {val:key for key, val in bb1_smiles2idx.items()}\n",
    "bb23_idx2smiles = {val:key for key, val in bb23_smiles2idx.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# おそらく使わない関数\n",
    "def replace_structure(main_mol, pattern_mol, replace_mol, idx=0):\n",
    "    \n",
    "    # patternにマッチする構造を削除して*に置き換える\n",
    "    if main_mol.HasSubstructMatch(pattern_mol):\n",
    "        main_mol = AllChem.ReplaceSubstructs(main_mol, pattern_mol, Chem.MolFromSmiles('*'))[idx]\n",
    "        # *をreplace_molで置き換える\n",
    "        main_mol = combine_fragments(main_mol, replace_mol)\n",
    "    \n",
    "    return main_mol\n",
    "\n",
    "# テスト\n",
    "bb1_smiles = \"C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21\"\n",
    "pattern = \"NC(=O)OCC1c2ccccc2-c2ccccc21\"\n",
    "bb1_replace = \"Nc1nc(N)nc(N)n1\"\n",
    "bb1_mol = Chem.MolFromSmiles(bb1_smiles)\n",
    "pattern_mol = Chem.MolFromSmiles(pattern)\n",
    "bb1_replace_mol = Chem.MolFromSmiles(bb1_replace)\n",
    "\n",
    "# replace_structure(bb1_mol, pattern_mol, bb1_replace_mol)\n",
    "AllChem.ReplaceSubstructs(bb1_mol, pattern_mol, bb1_replace_mol)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_capping_bb1_structure(main_smiles, del_t_butyl_halo_patterns=[], del_fluorene_halo_patterns=[], tert_butyl_ester_smiles=[],ex_dict={}):\n",
    "    \n",
    "    fluorene = Chem.MolFromSmiles(\"NC(=O)OCC1c2ccccc2-c2ccccc21\")\n",
    "    fluorene_without_n = Chem.MolFromSmiles(\"C(=O)OCC2c3ccccc3-c3ccccc32\")\n",
    "    fluorene_scaffold = Chem.MolFromSmiles(\"CC3c1ccccc1c2ccccc23\")\n",
    "    \n",
    "    dy_scaffold = Chem.MolFromSmiles(\"C[Dy]\")\n",
    "    \n",
    "    triazine = Chem.MolFromSmiles(\"Nc1nc(N)nc(N)n1\")\n",
    "    triazine_and_fluorene = Chem.MolFromSmiles(\"Nc7nc(NC3c1ccccc1c2ccccc23)nc(NC6c4ccccc4c5ccccc56)n7\")\n",
    "    triazine_and_Dy = Chem.MolFromSmiles(\"Nc7nc([Dy])nc([Dy])n7\")\n",
    "    \n",
    "    t_butyl_O = Chem.MolFromSmiles(\"COC(C)(C)(C)\")\n",
    "    carboxyl = Chem.MolFromSmiles(\"C(=O)O\")\n",
    "    \n",
    "    propane_ester = Chem.MolFromSmiles(\"C(=O)OCCCCCCC\")\n",
    "    fe_ester = Chem.MolFromSmiles(\"C(=O)O[Fe]\")\n",
    "    \n",
    "    metyl = Chem.MolFromSmiles(\"C\")\n",
    "    br = Chem.MolFromSmiles(\"Br\")\n",
    "    I = Chem.MolFromSmiles(\"I\")\n",
    "    Cl = Chem.MolFromSmiles(\"Cl\")\n",
    "    \n",
    "    # 例外処理\n",
    "    if main_smiles in ex_dict.keys():\n",
    "        return ex_dict[main_smiles]\n",
    "    \n",
    "    main_mol = Chem.MolFromSmiles(main_smiles)\n",
    "    \n",
    "    # fluoreneがなく、triazineにならないもの\n",
    "    for pattern in del_t_butyl_halo_patterns:\n",
    "        pattern_mol = Chem.MolFromSmiles(pattern)\n",
    "        if main_mol.HasSubstructMatch(pattern_mol):\n",
    "            main_mol = AllChem.ReplaceSubstructs(main_mol, t_butyl_O, dy_scaffold)[0]\n",
    "            main_mol = AllChem.ReplaceSubstructs(main_mol, br, dy_scaffold)[0]\n",
    "            main_mol = AllChem.ReplaceSubstructs(main_mol, I, dy_scaffold)[0]\n",
    "            main_mol = AllChem.ReplaceSubstructs(main_mol, Cl, dy_scaffold)[0]\n",
    "            # main_mol = AllChem.DeleteSubstructs(main_mol, t_butyl_O)\n",
    "            \n",
    "            \n",
    "            main_mol = AllChem.ReplaceSubstructs(main_mol, carboxyl, fe_ester)[0]\n",
    "            \n",
    "            main_smiles = Chem.MolToSmiles(main_mol)    \n",
    "            return main_smiles\n",
    "    \n",
    "    # fluoreneはあるがtriaineにならないもの\n",
    "    for pattern in del_fluorene_halo_patterns:\n",
    "        pattern_mol = Chem.MolFromSmiles(pattern)\n",
    "        if main_mol.HasSubstructMatch(pattern_mol):\n",
    "            main_mol = AllChem.ReplaceSubstructs(main_mol, fluorene_without_n, dy_scaffold)[0]\n",
    "            main_mol = AllChem.ReplaceSubstructs(main_mol, br, dy_scaffold)[0]\n",
    "            main_mol = AllChem.ReplaceSubstructs(main_mol, I, dy_scaffold)[0]\n",
    "            main_mol = AllChem.ReplaceSubstructs(main_mol, Cl, dy_scaffold)[0]\n",
    "            \n",
    "            main_mol = AllChem.ReplaceSubstructs(main_mol, carboxyl, fe_ester)[0]\n",
    "            main_smiles = Chem.MolToSmiles(main_mol)    \n",
    "            return main_smiles\n",
    "\n",
    "    \n",
    "    # fluorene→triazine\n",
    "    main_mol = AllChem.ReplaceSubstructs(main_mol, fluorene, triazine_and_Dy)[0]\n",
    "    \n",
    "    # carboxylをpropane_ester\n",
    "    if main_smiles in tert_butyl_ester_smiles:\n",
    "        main_mol = AllChem.ReplaceSubstructs(main_mol, carboxyl, fe_ester)[1]        \n",
    "    else:\n",
    "        main_mol = AllChem.ReplaceSubstructs(main_mol, carboxyl, fe_ester)[0]\n",
    " \n",
    "    main_smiles = Chem.MolToSmiles(main_mol)\n",
    "            \n",
    "    return main_smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainのbb1を一括で変換して確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trainのbb1を一括で見る\n",
    "df = df_train.copy()\n",
    "df = df.drop_duplicates([\"buildingblock1_smiles\"])\n",
    "df['main'] = df_train_orig.iloc[df.index][\"molecule_smiles\"].values\n",
    "df['buildingblock1_smiles'] = df['buildingblock1_smiles'].map(bb1_idx2smiles)\n",
    "df['buildingblock2_smiles'] = df['buildingblock2_smiles'].map(bb23_idx2smiles)\n",
    "df['buildingblock3_smiles'] = df['buildingblock3_smiles'].map(bb23_idx2smiles)\n",
    "temp = df.iloc[25]\n",
    "\n",
    "\n",
    "tert_butyl_ester_smiles = [\"CC(C)(C)OC(=O)CC(NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O\",\n",
    "                           \"CC(C)(C)OC(=O)CCC(NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O\",\n",
    "                           \"CC(C)(C)OC(=O)N1CCN(C(=O)OCC2c3ccccc3-c3ccccc32)C1C(=O)O\",\n",
    "                           \"CC(C)(C)OC(=O)N1C[C@@H](NC(=O)OCC2c3ccccc3-c3ccccc32)[C@H](C(=O)O)C1\",\n",
    "                           \"COC(=O)CC(NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O\",\n",
    "                           \"COC(=O)c1ccc(C(=O)O)c(NC(=O)OCC2c3ccccc3-c3ccccc32)c1\",\n",
    "                           ]\n",
    "\n",
    "# 207, 209, 270\n",
    "smiles = temp['buildingblock1_smiles']\n",
    "print(smiles)\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "mol\n",
    "\n",
    "smiles = clean_and_capping_bb1_structure(smiles, tert_butyl_ester_smiles=tert_butyl_ester_smiles)\n",
    "print(smiles)\n",
    "Chem.MolFromSmiles(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trainのbb1を一括で見る\n",
    "df = df_train.copy()\n",
    "df = df.drop_duplicates([\"buildingblock1_smiles\"])\n",
    "df['main'] = df_train_orig.iloc[df.index][\"molecule_smiles\"].values\n",
    "df['buildingblock1_smiles'] = df['buildingblock1_smiles'].map(bb1_idx2smiles)\n",
    "df['buildingblock2_smiles'] = df['buildingblock2_smiles'].map(bb23_idx2smiles)\n",
    "df['buildingblock3_smiles'] = df['buildingblock3_smiles'].map(bb23_idx2smiles)\n",
    "\n",
    "df['replaced'] = df['buildingblock1_smiles'].apply(lambda x: clean_and_capping_bb1_structure(x,tert_butyl_ester_smiles=tert_butyl_ester_smiles))\n",
    "\n",
    "col = ['buildingblock1_smiles',\"replaced\", 'main', 'buildingblock2_smiles','buildingblock3_smiles', ]\n",
    "# col = ['buildingblock2_smiles','buildingblock3_smiles', 'main']\n",
    "df[col] = df[col].applymap(lambda x: Chem.MolFromSmiles(x))\n",
    "\n",
    "i = 1\n",
    "chunk = 100\n",
    "mols_list = df.iloc[i*chunk:i*chunk+chunk][col].values.flatten()\n",
    "# mols_list = df[['buildingblock1_smiles','replaced', 'main', 'buildingblock2_smiles','buildingblock3_smiles']].values.flatten()\n",
    "label_list  = [str(i) for i in range(i*100, i*100+100) for _ in range(5)]\n",
    "\n",
    "img = Draw.MolsToGridImage(mols_list,\n",
    "                        molsPerRow=5, #一列に配置する分子の数\n",
    "                        subImgSize=(400,300),\n",
    "                        maxMols =len(mols_list)*5,\n",
    "                        legends=label_list\n",
    "                            )\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST MOLECULE も"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# デバッグ用\n",
    "df = df_test.copy()\n",
    "# trainに含まれるのは除く\n",
    "train_bb1_idx = df_train['buildingblock1_smiles'].unique().tolist()\n",
    "df = df.loc[~df_test['buildingblock1_smiles'].isin(train_bb1_idx)]\n",
    "df = df.drop_duplicates([\"buildingblock1_smiles\"])\n",
    "print(len(df))\n",
    "\n",
    "df['main'] = df_test_orig.iloc[df.index][\"molecule_smiles\"].values\n",
    "df['buildingblock1_smiles'] = df['buildingblock1_smiles'].map(bb1_idx2smiles)\n",
    "df['buildingblock2_smiles'] = df['buildingblock2_smiles'].map(bb23_idx2smiles)\n",
    "df['buildingblock3_smiles'] = df['buildingblock3_smiles'].map(bb23_idx2smiles)\n",
    "\n",
    "i = 69\n",
    "temp = df.iloc[i]\n",
    "smiles = temp['buildingblock1_smiles']\n",
    "print(smiles)\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "# mol = AllChem.DeleteSubstructs(mol, Chem.MolFromSmiles(\"CC(C)(C)O\"))\n",
    "mol = AllChem.ReplaceSubstructs(mol, Chem.MolFromSmiles(\"Br\"), Chem.MolFromSmiles(\"C\"))[0]\n",
    "mol = AllChem.ReplaceSubstructs(mol, Chem.MolFromSmiles(\"C(=O)OCC2c3ccccc3-c3ccccc32\"), Chem.MolFromSmiles(\"C\"))[0]\n",
    "mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_test.copy()\n",
    "\n",
    "# trainに含まれるのは除く\n",
    "train_bb1_idx = df_train['buildingblock1_smiles'].unique().tolist()\n",
    "df = df.loc[~df_test['buildingblock1_smiles'].isin(train_bb1_idx)]\n",
    "df = df.drop_duplicates([\"buildingblock1_smiles\"])\n",
    "print(len(df))\n",
    "\n",
    "df['main'] = df_test_orig.iloc[df.index][\"molecule_smiles\"].values\n",
    "df['buildingblock1_smiles'] = df['buildingblock1_smiles'].map(bb1_idx2smiles)\n",
    "df['buildingblock2_smiles'] = df['buildingblock2_smiles'].map(bb23_idx2smiles)\n",
    "df['buildingblock3_smiles'] = df['buildingblock3_smiles'].map(bb23_idx2smiles)\n",
    "\n",
    "del_t_butyl_halo_patterns = [\n",
    "    \"CC(C)(C)OC(=O)N1CC(c2ccccc2)=C[C@H]1C(=O)O\",\n",
    "    \"CC(C)(C)OC(=O)N1CCC(C(=O)O)(c2ccccc2)CC1\",\n",
    "    \"CC(C)(C)OC(=O)N1CCC(COc2ccccc2C(=O)O)CC1\",\n",
    "    \"CC(C)(C)OC(=O)N1CCC(COc2ccc(C(=O)O)cc2)CC1\",\n",
    "    \"CC(C)(C)OC(=O)N1CCC(Oc2cc(C(=O)O)ccc2I)CC1\",\n",
    "    \"CC(C)(C)OC(=O)N1CCC[C@@H](c2ccccc2)[C@@H]1C(=O)O\",\n",
    "    \"CC(C)(C)OC(=O)N1CCC[C@@H](n2cccc2C(=O)O)C1\",\n",
    "    \"CC(C)(C)OC(=O)N1CCC[C@H](n2cc(C(=O)O)c3ccccc32)C1\",\n",
    "    \"CC(C)(C)OC(=O)N1CC[C@@](Cc2cccs2)(C(=O)O)C1\",\n",
    "    \"CC(C)(C)OC(=O)N1CC[C@H](Oc2ccccc2C(=O)O)C1\",\n",
    "    \"CC(C)(C)OC(=O)N1CC[C@](Cc2ccccc2)(C(=O)O)C1\",\n",
    "    \"CC(C)(C)OC(=O)N1C[C@@H](C(=O)O)[C@H](c2ccccc2)C1\",\n",
    "    \"CC(C)(C)OC(=O)N1C[C@@H](Oc2ccccn2)C[C@@H]1C(=O)O\",\n",
    "    \"CC(C)(C)OC(=O)N1C[C@@H](n2cncc2)C[C@H]1C(=O)O\",\n",
    "    \"CC(C)(C)OC(=O)N1C[C@H](Oc2ccccc2)C[C@@H]1C(=O)O\",\n",
    "    \"CC(C)(C)OC(=O)N[C@@H]1CCCN(c2ncccc2C(=O)O)C1\",\n",
    "    \"CN(c1cc(C(=O)O)ccn1)C1CCN(C(=O)OC(C)(C)C)C1\",\n",
    "    ]\n",
    "del_fluorene_halo_patterns = [\n",
    "    \"CN(c1ncccc1C(=O)O)C1CCN(C(=O)OCC2c3ccccc3-c3ccccc32)C1\",\n",
    "    \"O=C(NC1CN(c2cc(C(=O)O)ccn2)C1)OCC1c2ccccc2-c2ccccc21\",\n",
    "    \"O=C(N[C@@H]1CCN(c2cc(C(=O)O)ccn2)C1)OCC1c2ccccc2-c2ccccc21\",\n",
    "    \"O=C(N[C@@H]1CCN(c2ncccc2C(=O)O)C1)OCC1c2ccccc2-c2ccccc21\",\n",
    "    \"O=C(O)[C@@H]1C=C(c2cccnc2)CN1C(=O)OCC1c2ccccc2-c2ccccc21\",\n",
    "    \"O=C(O)[C@@H]1C=C(c2ccncc2)CN1C(=O)OCC1c2ccccc2-c2ccccc21\",\n",
    "    \"O=C(O)[C@@H]1C=C(c2cncnc2)CN1C(=O)OCC1c2ccccc2-c2ccccc21\",\n",
    "    \"O=C(O)[C@@H]1CN(C(=O)OCC2c3ccccc3-c3ccccc32)C[C@H]1c1cccnc1\",\n",
    "    \"O=C(O)[C@@H]1CN(C(=O)OCC2c3ccccc3-c3ccccc32)C[C@H]1c1ccncc1\",\n",
    "    \"O=C(O)c1cccnc1N1CCCN(C(=O)OCC2c3ccccc3-c3ccccc32)CC1\",\n",
    "    \"O=C(O)c1cccnc1N1CCN(C(=O)OCC2c3ccccc3-c3ccccc32)CC1\",\n",
    "    \"O=C(O)c1ccnc(N2CCCN(C(=O)OCC3c4ccccc4-c4ccccc43)CC2)c1\",\n",
    "    \"O=C(O)c1ccnc(N2CCN(C(=O)OCC3c4ccccc4-c4ccccc43)CC2)c1\",\n",
    "    \"O=C(OCC1c2ccccc2-c2ccccc21)N1CCC(Cc2ccncc2)(C(=O)O)C1\",\n",
    "    \"O=C(OCC1c2ccccc2-c2ccccc21)N1CCC(Cc2ccncc2)(C(=O)O)CC1\",\n",
    "]\n",
    "\n",
    "tert_butyl_ester_smiles = [\"CC(C)(C)OC(=O)CC(NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O\",\n",
    "                           \"CC(C)(C)OC(=O)CCC(NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O\",\n",
    "                           \"CC(C)(C)OC(=O)N1CCN(C(=O)OCC2c3ccccc3-c3ccccc32)C1C(=O)O\",\n",
    "                           \"CC(C)(C)OC(=O)N1C[C@@H](NC(=O)OCC2c3ccccc3-c3ccccc32)[C@H](C(=O)O)C1\",\n",
    "                           \"COC(=O)CC(NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O\",\n",
    "                           \"COC(=O)c1ccc(C(=O)O)c(NC(=O)OCC2c3ccccc3-c3ccccc32)c1\",\n",
    "                           ]\n",
    "\n",
    "ex_dict = {}\n",
    "df['replaced'] = df['buildingblock1_smiles'].apply(lambda x: clean_and_capping_bb1_structure(x, \n",
    "                                                                                 del_t_butyl_halo_patterns=del_t_butyl_halo_patterns, \n",
    "                                                                                 del_fluorene_halo_patterns=del_fluorene_halo_patterns,\n",
    "                                                                                 tert_butyl_ester_smiles=tert_butyl_ester_smiles,\n",
    "                                                                                 ex_dict=ex_dict))\n",
    "\n",
    "col = ['buildingblock1_smiles',\"replaced\", 'main', 'buildingblock2_smiles','buildingblock3_smiles', ]\n",
    "df[col] = df[col].applymap(lambda x: Chem.MolFromSmiles(x))\n",
    "\n",
    "i = 0\n",
    "chunk = 100\n",
    "mols_list = df.iloc[i*chunk:i*chunk+chunk][col].values.flatten()\n",
    "label_list  = [str(i) for i in range(i*100, i*100+100) for _ in range(5)]\n",
    "\n",
    "img = Draw.MolsToGridImage(mols_list,\n",
    "                        molsPerRow=5, #一列に配置する分子の数\n",
    "                        subImgSize=(400,300),\n",
    "                        maxMols = len(mols_list)*5,\n",
    "                        legends = label_list,\n",
    "                            )\n",
    "img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一括チェック "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_test.copy()\n",
    "df = df.drop_duplicates([\"buildingblock1_smiles\"])\n",
    "print(len(df))\n",
    "\n",
    "df['main'] = df_test_orig.iloc[df.index][\"molecule_smiles\"].values\n",
    "df['buildingblock1_smiles'] = df['buildingblock1_smiles'].map(bb1_idx2smiles)\n",
    "df['buildingblock2_smiles'] = df['buildingblock2_smiles'].map(bb23_idx2smiles)\n",
    "df['buildingblock3_smiles'] = df['buildingblock3_smiles'].map(bb23_idx2smiles)\n",
    "df.iloc[145]['buildingblock1_smiles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_test.copy()\n",
    "df = df.drop_duplicates([\"buildingblock1_smiles\"])\n",
    "print(len(df))\n",
    "\n",
    "df['main'] = df_test_orig.iloc[df.index][\"molecule_smiles\"].values\n",
    "df['buildingblock1_smiles'] = df['buildingblock1_smiles'].map(bb1_idx2smiles)\n",
    "df['buildingblock2_smiles'] = df['buildingblock2_smiles'].map(bb23_idx2smiles)\n",
    "df['buildingblock3_smiles'] = df['buildingblock3_smiles'].map(bb23_idx2smiles)\n",
    "\n",
    "\n",
    "del_t_butyl_halo_patterns = [\n",
    "    \"CC(C)(C)OC(=O)N1CC(c2ccccc2)=C[C@H]1C(=O)O\",\n",
    "    \"CC(C)(C)OC(=O)N1CCC(C(=O)O)(c2ccccc2)CC1\",\n",
    "    \"CC(C)(C)OC(=O)N1CCC(COc2ccccc2C(=O)O)CC1\",\n",
    "    \"CC(C)(C)OC(=O)N1CCC(COc2ccc(C(=O)O)cc2)CC1\",\n",
    "    \"CC(C)(C)OC(=O)N1CCC(Oc2cc(C(=O)O)ccc2I)CC1\",\n",
    "    \"CC(C)(C)OC(=O)N1CCC[C@@H](c2ccccc2)[C@@H]1C(=O)O\",\n",
    "    \"CC(C)(C)OC(=O)N1CCC[C@@H](n2cccc2C(=O)O)C1\",\n",
    "    \"CC(C)(C)OC(=O)N1CCC[C@H](n2cc(C(=O)O)c3ccccc32)C1\",\n",
    "    \"CC(C)(C)OC(=O)N1CC[C@@](Cc2cccs2)(C(=O)O)C1\",\n",
    "    \"CC(C)(C)OC(=O)N1CC[C@H](Oc2ccccc2C(=O)O)C1\",\n",
    "    \"CC(C)(C)OC(=O)N1CC[C@](Cc2ccccc2)(C(=O)O)C1\",\n",
    "    \"CC(C)(C)OC(=O)N1C[C@@H](C(=O)O)[C@H](c2ccccc2)C1\",\n",
    "    \"CC(C)(C)OC(=O)N1C[C@@H](Oc2ccccn2)C[C@@H]1C(=O)O\",\n",
    "    \"CC(C)(C)OC(=O)N1C[C@@H](n2cncc2)C[C@H]1C(=O)O\",\n",
    "    \"CC(C)(C)OC(=O)N1C[C@H](Oc2ccccc2)C[C@@H]1C(=O)O\",\n",
    "    \"CC(C)(C)OC(=O)N[C@@H]1CCCN(c2ncccc2C(=O)O)C1\",\n",
    "    \"CN(c1cc(C(=O)O)ccn1)C1CCN(C(=O)OC(C)(C)C)C1\",\n",
    "    ]\n",
    "del_fluorene_halo_patterns = [\n",
    "    \"CN(c1ncccc1C(=O)O)C1CCN(C(=O)OCC2c3ccccc3-c3ccccc32)C1\",\n",
    "    \"O=C(NC1CN(c2cc(C(=O)O)ccn2)C1)OCC1c2ccccc2-c2ccccc21\",\n",
    "    \"O=C(N[C@@H]1CCN(c2cc(C(=O)O)ccn2)C1)OCC1c2ccccc2-c2ccccc21\",\n",
    "    \"O=C(N[C@@H]1CCN(c2ncccc2C(=O)O)C1)OCC1c2ccccc2-c2ccccc21\",\n",
    "    \"O=C(O)[C@@H]1C=C(c2cccnc2)CN1C(=O)OCC1c2ccccc2-c2ccccc21\",\n",
    "    \"O=C(O)[C@@H]1C=C(c2ccncc2)CN1C(=O)OCC1c2ccccc2-c2ccccc21\",\n",
    "    \"O=C(O)[C@@H]1C=C(c2cncnc2)CN1C(=O)OCC1c2ccccc2-c2ccccc21\",\n",
    "    \"O=C(O)[C@@H]1CN(C(=O)OCC2c3ccccc3-c3ccccc32)C[C@H]1c1cccnc1\",\n",
    "    \"O=C(O)[C@@H]1CN(C(=O)OCC2c3ccccc3-c3ccccc32)C[C@H]1c1ccncc1\",\n",
    "    \"O=C(O)c1cccnc1N1CCCN(C(=O)OCC2c3ccccc3-c3ccccc32)CC1\",\n",
    "    \"O=C(O)c1cccnc1N1CCN(C(=O)OCC2c3ccccc3-c3ccccc32)CC1\",\n",
    "    \"O=C(O)c1ccnc(N2CCCN(C(=O)OCC3c4ccccc4-c4ccccc43)CC2)c1\",\n",
    "    \"O=C(O)c1ccnc(N2CCN(C(=O)OCC3c4ccccc4-c4ccccc43)CC2)c1\",\n",
    "    \"O=C(OCC1c2ccccc2-c2ccccc21)N1CCC(Cc2ccncc2)(C(=O)O)C1\",\n",
    "    \"O=C(OCC1c2ccccc2-c2ccccc21)N1CCC(Cc2ccncc2)(C(=O)O)CC1\",\n",
    "]\n",
    "tert_butyl_ester_smiles = [\"CC(C)(C)OC(=O)CC(NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O\",\n",
    "                           \"CC(C)(C)OC(=O)CCC(NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O\",\n",
    "                           \"CC(C)(C)OC(=O)N1CCN(C(=O)OCC2c3ccccc3-c3ccccc32)C1C(=O)O\",\n",
    "                           \"CC(C)(C)OC(=O)N1C[C@@H](NC(=O)OCC2c3ccccc3-c3ccccc32)[C@H](C(=O)O)C1\",\n",
    "                           \"COC(=O)CC(NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O\",\n",
    "                           \"COC(=O)c1ccc(C(=O)O)c(NC(=O)OCC2c3ccccc3-c3ccccc32)c1\",\n",
    "                           ]\n",
    "ex_dict = {}\n",
    "df['replaced'] = df['buildingblock1_smiles'].apply(lambda x: clean_and_capping_bb1_structure(x, \n",
    "                                                                                 del_t_butyl_halo_patterns=del_t_butyl_halo_patterns, \n",
    "                                                                                 del_fluorene_halo_patterns=del_fluorene_halo_patterns,\n",
    "                                                                                 tert_butyl_ester_smiles=tert_butyl_ester_smiles,\n",
    "                                                                                 ex_dict=ex_dict))\n",
    "\n",
    "col = ['buildingblock1_smiles','replaced', 'buildingblock2_smiles','buildingblock3_smiles', 'main']\n",
    "col_mols = [f'{c}_mol' for c in col]\n",
    "\n",
    "df[col_mols] = df[col].applymap(lambda x: Chem.MolFromSmiles(x))\n",
    "\n",
    "i = 2\n",
    "chunk = 10\n",
    "mols_list = df.iloc[i*chunk:i*chunk+chunk][col_mols].values.flatten()\n",
    "label_list  = [str(i) for i in range(chunk) for _ in range(5)]\n",
    "\n",
    "img = Draw.MolsToGridImage(mols_list,\n",
    "                        molsPerRow=5, #一列に配置する分子の数\n",
    "                        subImgSize=(400,300),\n",
    "                        maxMols = len(mols_list)*5,\n",
    "                        legends = label_list,\n",
    "                            )\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 記述子計算\n",
    "from rdkit.Chem import AllChem, Descriptors\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "from mordred import Calculator, descriptors \n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "\n",
    "mols_list = df['replaced_mol'].values.tolist()\n",
    "descriptor_names = [desc_name for desc_name, _ in Descriptors.descList]\n",
    "descriptor_calculation = MoleculeDescriptors.MolecularDescriptorCalculator(descriptor_names)\n",
    "RDkit = [descriptor_calculation.CalcDescriptors(mol_temp) for mol_temp in mols_list]\n",
    "df_RDkit = pd.DataFrame(RDkit, columns = descriptor_names)\n",
    "df_RDkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
