{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概要\n",
    "- trainとtestのbbをまとめる（indexずれを防ぐため）\n",
    "- BB1のscaffoldの情報を使って、FOLDを設定する\n",
    "- bb1~3と同様にbb1もindex化して列を足し、scaffold用の辞書も準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def is_kaggle_kernel():\n",
    "    return os.path.exists('/kaggle/working')\n",
    "\n",
    "if is_kaggle_kernel():\n",
    "\n",
    "    BASE_DIR = Path(\"/kaggle\")\n",
    "    DATA_DIR = BASE_DIR / \"input\"\n",
    "    OUTPUT_DIR = BASE_DIR / \"working\"\n",
    "    print('on kaggle notebook')\n",
    "\n",
    "else:\n",
    "    BASE_DIR = Path(os.getcwd()) / './../'\n",
    "    DATA_DIR = BASE_DIR / \"data\"\n",
    "    OUTPUT_DIR = BASE_DIR / \"output/eda\"\n",
    "    \n",
    "class paths:    \n",
    "    DATA_DIR = DATA_DIR\n",
    "    TRAIN_PATH = DATA_DIR / \"train.parquet\"\n",
    "    TEST_PATH = DATA_DIR / \"test.parquet\"\n",
    "    OUTPUT_DIR = OUTPUT_DIR\n",
    "    SHRUNKEN_DATA_DIR = DATA_DIR / \"shrunken-train-set\"\n",
    "    \n",
    "    OUTPUT_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 必要なデータ\n",
    "- smiles to indexの辞書, index to smilesの辞書\n",
    "    - bb1\n",
    "    - bb1 scaffold\n",
    "    - bb2, 3 scaffold\n",
    "    - bb2, 3 scaffold\n",
    "    - main moleculeの scaffoldの辞書\n",
    "\n",
    "- shrunkenしたテストデータ\n",
    "    - train\n",
    "    - test（pretrain用）\n",
    "- non shrunken test（submitt用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "# import duckdb\n",
    "# import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mainの骨格のscaffoldから"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_cols = ['molecule_smiles']\n",
    "TARGETS = ['binds_BRD4', 'binds_HSA','binds_sEH']\n",
    "\n",
    "df_train_main = pd.read_parquet(paths.DATA_DIR / 'shrunken-train-set/train.parquet', columns=bb_cols)\n",
    "df_test_main = pd.read_parquet(paths.DATA_DIR / 'shrunken-train-set/test.parquet', columns=bb_cols)\n",
    "\n",
    "# submit用のtestデータ\n",
    "df_sub_main = pd.read_parquet(paths.DATA_DIR / 'test.parquet', columns=['id']+bb_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def convert_scaffold(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    scaffold = MurckoScaffold.GetScaffoldForMol(mol)\n",
    "    scaffold_smiles = Chem.MolToSmiles(scaffold)\n",
    "    \n",
    "    return scaffold_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98415610 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 45454714/98415610 [1:02:55<556:20:59, 26.44it/s]/usr/local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "100%|██████████| 98415610/98415610 [6:28:38<00:00, 4220.50it/s]   \n"
     ]
    }
   ],
   "source": [
    "smiles_list  = df_train_main['molecule_smiles'].values.tolist()\n",
    "train_scaffold = Parallel(n_jobs=16)(delayed(convert_scaffold)(smiles) for smiles in tqdm(smiles_list))\n",
    "df_train_main['molecule_smiles'] = train_scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878022/878022 [00:34<00:00, 25577.02it/s]\n"
     ]
    }
   ],
   "source": [
    "smiles_list  = df_test_main['molecule_smiles'].values.tolist()\n",
    "test_scaffold = Parallel(n_jobs=8)(delayed(convert_scaffold)(smiles) for smiles in tqdm(smiles_list))\n",
    "df_test_main['molecule_smiles'] = test_scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1674896/1674896 [01:13<00:00, 22643.25it/s]\n"
     ]
    }
   ],
   "source": [
    "smiles_list  = df_sub_main['molecule_smiles'].values.tolist()\n",
    "df_sub_main['molecule_smiles'] = Parallel(n_jobs=8)(delayed(convert_scaffold)(smiles) for smiles in tqdm(smiles_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaffold_set = sorted(list(set(test_scaffold)|set(test_scaffold)))\n",
    "scaffold_smiles2idx = {scaffold: i for i, scaffold in enumerate(scaffold_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_main['molecule_smiles'] = df_train_main['molecule_smiles'].map(scaffold_smiles2idx)\n",
    "df_test_main['molecule_smiles'] = df_test_main['molecule_smiles'].map(scaffold_smiles2idx)\n",
    "df_sub_main['molecule_smiles'] = df_sub_main['molecule_smiles'].map(scaffold_smiles2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_main.to_parquet(paths.DATA_DIR / 'shrunken-data/train_main_scaffold.parquet')\n",
    "df_test_main.to_parquet(paths.DATA_DIR / 'shrunken-data/test_main_scaffold.parquet')\n",
    "df_sub_main.to_parquet(paths.DATA_DIR / 'shrunken-data/sub_main_scaffold.parquet')\n",
    "\n",
    "# scaffold_smiles2idxを保存\n",
    "with open(paths.DATA_DIR / 'shrunken-data/scaffold_smiles2idx.pickle', 'wb') as f:\n",
    "    pickle.dump(scaffold_smiles2idx, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
