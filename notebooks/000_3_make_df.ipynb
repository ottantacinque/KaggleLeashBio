{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概要\n",
    "- BB1のscaffoldの情報を使って、FOLDを設定する\n",
    "- bb1~3と同様にbb1もindex化して列を足し、scaffold用の辞書も準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def is_kaggle_kernel():\n",
    "    return os.path.exists('/kaggle/working')\n",
    "\n",
    "if is_kaggle_kernel():\n",
    "\n",
    "    BASE_DIR = Path(\"/kaggle\")\n",
    "    DATA_DIR = BASE_DIR / \"input\"\n",
    "    OUTPUT_DIR = BASE_DIR / \"working\"\n",
    "    print('on kaggle notebook')\n",
    "\n",
    "else:\n",
    "    BASE_DIR = Path(os.getcwd()) / './../'\n",
    "    DATA_DIR = BASE_DIR / \"data\"\n",
    "    OUTPUT_DIR = BASE_DIR / \"output/eda\"\n",
    "    \n",
    "class paths:    \n",
    "    DATA_DIR = DATA_DIR\n",
    "    TRAIN_PATH = DATA_DIR / \"train.parquet\"\n",
    "    TEST_PATH = DATA_DIR / \"test.parquet\"\n",
    "    OUTPUT_DIR = OUTPUT_DIR\n",
    "    SHRUNKEN_DATA_DIR = DATA_DIR / \"shrunken-train-set\"\n",
    "    \n",
    "    OUTPUT_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2023.9.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.22.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "# import duckdb\n",
    "# import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "\n",
    "import pickle\n",
    "\n",
    "# 乱数をデフォルトで固定\n",
    "# 乱数をデフォルトで固定\n",
    "import random\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_cols = ['buildingblock1_smiles', 'buildingblock2_smiles','buildingblock3_smiles', \n",
    "        #    'molecule_smiles'\n",
    "           ]\n",
    "TARGETS = ['binds_BRD4', 'binds_HSA','binds_sEH']\n",
    "\n",
    "df_train = pd.read_parquet(paths.DATA_DIR / 'shrunken-train-set/train.parquet', columns=bb_cols + TARGETS)\n",
    "df_test = pd.read_parquet(paths.DATA_DIR / 'shrunken-train-set/test.parquet', columns=bb_cols)\n",
    "\n",
    "# building block smiles\n",
    "# NOTE: trainとtestのindexとsmilesは一致していないっぽい\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'train_dicts/BBs_dict_reverse_1.p', 'rb') as file:\n",
    "    train_dicts_bb1 = pickle.load(file)\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'train_dicts/BBs_dict_reverse_2.p', 'rb') as file:\n",
    "    train_dicts_bb2 = pickle.load(file)\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'train_dicts/BBs_dict_reverse_3.p', 'rb') as file:\n",
    "    train_dicts_bb3 = pickle.load(file)\n",
    "\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'test_dicts/BBs_dict_reverse_1_test.p', 'rb') as file:\n",
    "    test_dicts_bb1 = pickle.load(file)\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'test_dicts/BBs_dict_reverse_2_test.p', 'rb') as file:\n",
    "    test_dicts_bb2 = pickle.load(file)\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'test_dicts/BBs_dict_reverse_3_test.p', 'rb') as file:\n",
    "    test_dicts_bb3= pickle.load(file)\n",
    "    \n",
    "train_dicts_bb1_reverse = {val:key for key, val in train_dicts_bb1.items()}\n",
    "train_dicts_bb2_reverse = {val:key for key, val in train_dicts_bb2.items()}\n",
    "train_dicts_bb3_reverse = {val:key for key, val in train_dicts_bb3.items()}\n",
    "test_dicts_bb1_reverse = {val:key for key, val in test_dicts_bb1.items()}\n",
    "test_dicts_bb2_reverse = {val:key for key, val in test_dicts_bb2.items()}\n",
    "test_dicts_bb3_reverse = {val:key for key, val in test_dicts_bb3.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb1_smiles_train = [smiles for smiles in train_dicts_bb1.values()]\n",
    "bb2_smiles_train = [smiles for smiles in train_dicts_bb2.values()]\n",
    "bb3_smiles_train = [smiles for smiles in train_dicts_bb3.values()]\n",
    "bb1_smiles_test = [smiles for smiles in test_dicts_bb1.values()]\n",
    "bb2_smiles_test = [smiles for smiles in test_dicts_bb2.values()]\n",
    "bb3_smiles_test = [smiles for smiles in test_dicts_bb3.values()]\n",
    "\n",
    "bb1_mols_train = [Chem.MolFromSmiles(smiles) for smiles in bb1_smiles_train]\n",
    "bb2_mols_train = [Chem.MolFromSmiles(smiles) for smiles in bb2_smiles_train]\n",
    "bb3_mols_train = [Chem.MolFromSmiles(smiles) for smiles in bb3_smiles_train]\n",
    "bb1_mols_test = [Chem.MolFromSmiles(smiles) for smiles in bb1_smiles_test]\n",
    "bb2_mols_test = [Chem.MolFromSmiles(smiles) for smiles in bb2_smiles_test]\n",
    "bb3_mols_test = [Chem.MolFromSmiles(smiles) for smiles in bb3_smiles_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分子をscaffoldごとにクラスタリングする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 271/271 [00:00<00:00, 3849.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# bb1のscaffoldを取得\n",
    "scaffold_dict = {}\n",
    "for smiles in tqdm(bb1_smiles_train):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    scaffold = MurckoScaffold.GetScaffoldForMol(mol)\n",
    "    scaffold_smiles = Chem.MolToSmiles(scaffold)\n",
    "    \n",
    "    scaffold_dict[smiles] = scaffold_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ※ train dataの処理\n",
    "# scaffold → intの辞書を作成\n",
    "scaffold_list = list(set([s for s in scaffold_dict.values()]))\n",
    "scaffold_list.sort()\n",
    "\n",
    "scaffold_idx_dict = {s:num for num, s in enumerate(scaffold_list)}\n",
    "scaffold_idx_dict_reverse = {num:s for num, s in enumerate(scaffold_list)}\n",
    "\n",
    "# 保存\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'train_dicts/BBs_scaffold_dict_1.p', mode='wb') as f:\n",
    "    pickle.dump(scaffold_idx_dict, f)\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'train_dicts/BBs_scaffold_dict_reverse_1.p', mode='wb') as f:\n",
    "    pickle.dump(scaffold_idx_dict_reverse, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 63)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# タニモト係数に応じてグループ分け\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "\n",
    "scaffold_mols = [Chem.MolFromSmiles(s) for s in scaffold_list]\n",
    "morgan_fp = [AllChem.GetMorganFingerprintAsBitVect(x, 2, 2048) for x in scaffold_mols]\n",
    "\n",
    "dis_matrix = [DataStructs.BulkTanimotoSimilarity(morgan_fp[i], morgan_fp, returnDistance=True) for i in range(len(morgan_fp))]\n",
    "### numpy.ndarrayへの変換\n",
    "dis_array = np.array(dis_matrix)\n",
    "dis_array.shape ### (5000, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各クラスタのscaffold数\n",
      "3    19\n",
      "4    16\n",
      "0    15\n",
      "1    12\n",
      "2     1\n",
      "dtype: int64\n",
      "各クラスタのscaffold数(修正後)\n",
      "0 15\n",
      "1 12\n",
      "2 1\n",
      "3 19\n",
      "4 16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=5)\n",
    "kmeans.fit(dis_array)\n",
    "\n",
    "print('各クラスタのscaffold数')\n",
    "print(pd.value_counts(kmeans.labels_))\n",
    "\n",
    "fold_scaffold_dict = {i: [] for i in range(5)}\n",
    "for n,j in enumerate(kmeans.labels_):\n",
    "    fold_scaffold_dict[j].append(scaffold_list[n])\n",
    "    \n",
    "# fold1のscaffoldの4番目だけをfold0にして、それ以外ををfold0に押し込む（圧倒的に数が多いので）\n",
    "# num = 4\n",
    "# fold_scaffold_dict[0].extend(fold_scaffold_dict[1][:num] + fold_scaffold_dict[1][num+1:])\n",
    "# fold_scaffold_dict[1] = [fold_scaffold_dict[1][num]]\n",
    "\n",
    "print('各クラスタのscaffold数(修正後)')\n",
    "for fold, s_list in fold_scaffold_dict.items():\n",
    "    print(fold, len(s_list))\n",
    "\n",
    "fold_scaffold_dict_reverse = {}\n",
    "# key, valの入れ替え\n",
    "for fold, s_list in fold_scaffold_dict.items():\n",
    "    for s in s_list:\n",
    "        fold_scaffold_dict_reverse[s] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    44307006\n",
       "0    27966077\n",
       "4    10163121\n",
       "1     8718245\n",
       "2     7261161\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bb1_idx_to_fold(bb1_idx):\n",
    "    bb1_smiles = train_dicts_bb1[bb1_idx]\n",
    "    bb1_scaffold_smi = scaffold_dict[bb1_smiles]\n",
    "    fold = fold_scaffold_dict_reverse[bb1_scaffold_smi]\n",
    "    return fold\n",
    "\n",
    "# 辞書にする\n",
    "bb1idx2fold = {bb1_idx:bb1_idx_to_fold(bb1_idx) for bb1_idx in df_train['buildingblock1_smiles'].unique()}\n",
    "\n",
    "df_train['fold'] = df_train['buildingblock1_smiles'].map(bb1idx2fold)\n",
    "df_train['fold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold0\n",
      "binds_BRD4    0.005811\n",
      "binds_HSA     0.004069\n",
      "binds_sEH     0.004720\n",
      "dtype: float64\n",
      "---\n",
      "fold1\n",
      "binds_BRD4    0.002707\n",
      "binds_HSA     0.003055\n",
      "binds_sEH     0.001804\n",
      "dtype: float64\n",
      "---\n",
      "fold2\n",
      "binds_BRD4    0.012648\n",
      "binds_HSA     0.004856\n",
      "binds_sEH     0.003451\n",
      "dtype: float64\n",
      "---\n",
      "fold3\n",
      "binds_BRD4    0.002994\n",
      "binds_HSA     0.004585\n",
      "binds_sEH     0.002315\n",
      "dtype: float64\n",
      "---\n",
      "fold4\n",
      "binds_BRD4    0.004564\n",
      "binds_HSA     0.002907\n",
      "binds_sEH     0.044195\n",
      "dtype: float64\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# >>> fold2のbinds_sEHだけ以上に多い\n",
    "for fold in range(5):\n",
    "    print(f'fold{fold}')\n",
    "    print(df_train[df_train['fold'] == fold][TARGETS].mean())\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scaffold idx を df に足しておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb1_idx_to_scaffold_idx(bb1_idx):\n",
    "    bb1_smiles = train_dicts_bb1[bb1_idx]\n",
    "    bb1_scaffold_smi = scaffold_dict[bb1_smiles]\n",
    "    scaffold_idx = scaffold_idx_dict[bb1_scaffold_smi]\n",
    "    return scaffold_idx\n",
    "\n",
    "# 辞書にする（bb1_idx → scaffold_idx）\n",
    "bb1idx2scaidx = {bb1_idx:bb1_idx_to_scaffold_idx(bb1_idx) for bb1_idx in df_train['buildingblock1_smiles'].unique()}\n",
    "\n",
    "df_train['bb1_scaffold_idx'] = df_train['buildingblock1_smiles'].map(bb1idx2scaidx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 341/341 [00:00<00:00, 3763.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# bb1のscaffoldを取得\n",
    "scaffold_dict = {}\n",
    "for smiles in tqdm(bb1_smiles_test):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    scaffold = MurckoScaffold.GetScaffoldForMol(mol)\n",
    "    scaffold_smiles = Chem.MolToSmiles(scaffold)\n",
    "    \n",
    "    scaffold_dict[smiles] = scaffold_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaffold → intの辞書を作成\n",
    "scaffold_list = list(set([s for s in scaffold_dict.values()]))\n",
    "scaffold_list.sort()\n",
    "\n",
    "scaffold_idx_dict = {s:num for num, s in enumerate(scaffold_list)}\n",
    "scaffold_idx_dict_reverse = {num:s for num, s in enumerate(scaffold_list)}\n",
    "\n",
    "# 保存\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'test_dicts/BBs_scaffold_dict_1.p', mode='wb') as f:\n",
    "    pickle.dump(scaffold_idx_dict, f)\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'test_dicts/BBs_scaffold_dict_reverse_1.p', mode='wb') as f:\n",
    "    pickle.dump(scaffold_idx_dict_reverse, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb1_idx_to_scaffold_idx(bb1_idx):\n",
    "    bb1_smiles = test_dicts_bb1[bb1_idx]\n",
    "    bb1_scaffold_smi = scaffold_dict[bb1_smiles]\n",
    "    scaffold_idx = scaffold_idx_dict[bb1_scaffold_smi]\n",
    "    return scaffold_idx\n",
    "\n",
    "# 辞書にする（bb1_idx → scaffold_idx）\n",
    "bb1idx2scaidx = {bb1_idx:bb1_idx_to_scaffold_idx(bb1_idx) for bb1_idx in df_test['buildingblock1_smiles'].unique()}\n",
    "df_test['bb1_scaffold_idx'] = df_test['buildingblock1_smiles'].map(bb1idx2scaidx)\n",
    "\n",
    "# コード実行時に必要になるので辞書も保存しておく\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'test_dicts/BBs_idx_to_scaffold_idx_dict_1.p', mode='wb') as f:\n",
    "    pickle.dump(bb1idx2scaidx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 保存\n",
    "df_train.to_parquet(paths.SHRUNKEN_DATA_DIR / 'train_fold.parquet')\n",
    "df_test.to_parquet(paths.SHRUNKEN_DATA_DIR / 'test_fold.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
