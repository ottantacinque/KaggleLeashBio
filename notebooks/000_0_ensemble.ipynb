{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(os.getcwd()) / './../'\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "OUTPUT_DIR = BASE_DIR / f\"output\"\n",
    "\n",
    "ENS_OUTPUT_DIR  = OUTPUT_DIR / \"ensemble\"\n",
    "ENS_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_no_list = [\n",
    "                '015', # 0.455\n",
    "               '016', # 0.447  mordred\n",
    "               \"031\", # 0.451 headそう減らした\n",
    "               \"034\", # 0.451 mainのECFP4をあてる\n",
    "               '037', # 0.457 データの取り方変えた\n",
    "            #    '037_45', # 0.457 データの取り方変えた\n",
    "            #    '037_42', # 0.457 データの取り方変えた\n",
    "               \"043\", # 0.45 bb23のscaffold使った\n",
    "               \"044\", # 0.452 037のfold変えた版\n",
    "               \n",
    "               \"046\", # 0.443 2層目のFCをまとめた\n",
    "            #    \"049\", # 0.448 bb23だけ綺麗にしたもの\n",
    "            #    \"050\", # 0.448 scaffoldも含め全てクリーニングしたもの\n",
    "               \"051\", # 0.448 全データ使用\n",
    "            #    \"052\", # 0.443 ソフトラベリング\n",
    "               \"054\", # 0.457 tokenのモデルも組み込んだ\n",
    "               \"056\", # 0.451 結合部位をきゃっピングしたもの\n",
    "               ] # \n",
    "\n",
    "# exp_no_list = [\n",
    "#     # \"062\",\n",
    "#     # \"063\",\n",
    "#     \"064\",\n",
    "#     \"064_42\",\n",
    "#     # \"065\",\n",
    "#     # \"066\",\n",
    "#     # \"067\",    \n",
    "#     # \"068\",    \n",
    "#     \"069\",\n",
    "#     \"070\",\n",
    "#     \"070_717\",\n",
    "#     # \"071\",\n",
    "#     # \"072\",#ボツ\n",
    "#     \"072_524\",\n",
    "#     # \"073\",\n",
    "#     # \"073_2\",\n",
    "#     \"074\",\n",
    "#     # \"076\",#ボツ\n",
    "#     \"077_1024\",\n",
    "#     \"078_1123\",\n",
    "#     \"078_5\", # 計算待ち\n",
    "#     \"079_123\",\n",
    "#     # \"079_3\", # 計算待ち\n",
    "#     \"080_125\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/KaggleLeashBio/notebooks/../output/exp064/exp064_submission_1st.csv\n",
      "/workspaces/KaggleLeashBio/notebooks/../output/exp064_42/exp064_42_submission_1st.csv\n",
      "/workspaces/KaggleLeashBio/notebooks/../output/exp069/exp069_submission_1st.csv\n",
      "/workspaces/KaggleLeashBio/notebooks/../output/exp070/exp070_submission_1st.csv\n",
      "/workspaces/KaggleLeashBio/notebooks/../output/exp070_717/exp070_717_submission_1st.csv\n",
      "/workspaces/KaggleLeashBio/notebooks/../output/exp072_524/exp072_524_submission_1st.csv\n",
      "/workspaces/KaggleLeashBio/notebooks/../output/exp074/exp074_submission_1st.csv\n",
      "/workspaces/KaggleLeashBio/notebooks/../output/exp077_1024/exp077_1024_submission_1st.csv\n",
      "/workspaces/KaggleLeashBio/notebooks/../output/exp078_1123/exp078_1123_submission_1st.csv\n",
      "/workspaces/KaggleLeashBio/notebooks/../output/exp078_5/exp078_5_submission_1st.csv\n",
      "/workspaces/KaggleLeashBio/notebooks/../output/exp079_123/exp079_123_submission_1st.csv\n",
      "/workspaces/KaggleLeashBio/notebooks/../output/exp080_125/exp080_125_submission_1st.csv\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "for exp in exp_no_list:\n",
    "    try:\n",
    "        path = OUTPUT_DIR / f\"exp{exp}\" / f\"exp{exp}_submission.csv\"\n",
    "        df_temp = pd.read_csv(path)\n",
    "    except:\n",
    "        path = OUTPUT_DIR / f\"exp{exp}\" / f\"exp{exp}_submission_1st.csv\"\n",
    "        df_temp = pd.read_csv(path)\n",
    "    print(path)\n",
    "    preds.append(df_temp['binds'].values)\n",
    "    \n",
    "preds = np.mean(preds, axis=0)\n",
    "\n",
    "df_temp['binds'] = preds\n",
    "df_temp[['id', 'binds']].to_csv(ENS_OUTPUT_DIR / f\"submission_{'_'.join(exp_no_list)}.csv\", index = False)\n",
    "\n",
    "df_sigmoid = df_temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_064_064_42_069_070_070_717_072_524_074_077_1024_078_1123_078_5_079_123_080_125.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"submission_{'_'.join(exp_no_list)}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logitの状態でアンサンブルするコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# def sigmoid(x):\n",
    "#     return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# def logit(p):\n",
    "#     return np.log(p / (1 - p))\n",
    "\n",
    "# preds = []\n",
    "\n",
    "# for exp in exp_no_list:\n",
    "#     try:\n",
    "#         path = OUTPUT_DIR / f\"exp{exp}\" / f\"exp{exp}_submission.csv\"\n",
    "#         df_temp = pd.read_csv(path)\n",
    "#     except:\n",
    "#         path = OUTPUT_DIR / f\"exp{exp}\" / f\"exp{exp}_submission_1st.csv\"\n",
    "#         df_temp = pd.read_csv(path)\n",
    "#     print(path)\n",
    "#     preds.append(logit(df_temp['binds'].values))\n",
    "\n",
    "# # ロジットの平均を取る\n",
    "# logit_mean = np.mean(preds, axis=0)\n",
    "\n",
    "# # 平均ロジットを確率に戻す\n",
    "# preds = sigmoid(logit_mean)\n",
    "\n",
    "# df_temp['binds'] = preds\n",
    "# df_temp[['id', 'binds']].to_csv(ENS_OUTPUT_DIR / f\"submission_{'_'.join(exp_no_list)}_logit.csv\", index = False)\n",
    "\n",
    "# df_logit = df_temp.copy()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8006601,
     "sourceId": 67356,
     "sourceType": "competition"
    },
    {
     "datasetId": 4914065,
     "sourceId": 8275617,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
