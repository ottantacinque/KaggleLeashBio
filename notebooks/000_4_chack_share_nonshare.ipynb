{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概要\n",
    "test dataのうち、share, non-shareをしらべる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def is_kaggle_kernel():\n",
    "    return os.path.exists('/kaggle/working')\n",
    "\n",
    "if is_kaggle_kernel():\n",
    "\n",
    "    BASE_DIR = Path(\"/kaggle\")\n",
    "    DATA_DIR = BASE_DIR / \"input\"\n",
    "    OUTPUT_DIR = BASE_DIR / \"working\"\n",
    "    print('on kaggle notebook')\n",
    "\n",
    "else:\n",
    "    BASE_DIR = Path(os.getcwd()) / './../'\n",
    "    DATA_DIR = BASE_DIR / \"data\"\n",
    "    OUTPUT_DIR = BASE_DIR / \"output/eda\"\n",
    "    \n",
    "class paths:    \n",
    "    DATA_DIR = DATA_DIR\n",
    "    TRAIN_PATH = DATA_DIR / \"train.parquet\"\n",
    "    TEST_PATH = DATA_DIR / \"test.parquet\"\n",
    "    OUTPUT_DIR = OUTPUT_DIR\n",
    "    SHRUNKEN_DATA_DIR = DATA_DIR / \"shrunken-train-set\"\n",
    "    MY_DATA_DIR = DATA_DIR / \"my-data\"\n",
    "    \n",
    "    MY_DATA_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    OUTPUT_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "# import duckdb\n",
    "# import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_cols = ['buildingblock1_smiles', 'buildingblock2_smiles','buildingblock3_smiles']\n",
    "TARGETS = ['binds_BRD4', 'binds_HSA','binds_sEH']\n",
    "\n",
    "df_train = pd.read_parquet(paths.DATA_DIR / 'shrunken-train-set/train.parquet', columns=bb_cols + TARGETS)\n",
    "df_test = pd.read_parquet(paths.DATA_DIR / 'shrunken-train-set/test.parquet', columns=bb_cols)\n",
    "\n",
    "# building block smiles\n",
    "# NOTE: trainとtestのindexとsmilesは一致していないっぽい\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'train_dicts/BBs_dict_reverse_1.p', 'rb') as file:\n",
    "    train_dicts_bb1 = pickle.load(file)\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'train_dicts/BBs_dict_reverse_2.p', 'rb') as file:\n",
    "    train_dicts_bb2 = pickle.load(file)\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'train_dicts/BBs_dict_reverse_3.p', 'rb') as file:\n",
    "    train_dicts_bb3 = pickle.load(file)\n",
    "\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'test_dicts/BBs_dict_reverse_1_test.p', 'rb') as file:\n",
    "    test_dicts_bb1 = pickle.load(file)\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'test_dicts/BBs_dict_reverse_2_test.p', 'rb') as file:\n",
    "    test_dicts_bb2 = pickle.load(file)\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'test_dicts/BBs_dict_reverse_3_test.p', 'rb') as file:\n",
    "    test_dicts_bb3= pickle.load(file)\n",
    "    \n",
    "train_dicts_bb1_reverse = {val:key for key, val in train_dicts_bb1.items()}\n",
    "train_dicts_bb2_reverse = {val:key for key, val in train_dicts_bb2.items()}\n",
    "train_dicts_bb3_reverse = {val:key for key, val in train_dicts_bb3.items()}\n",
    "test_dicts_bb1_reverse = {val:key for key, val in test_dicts_bb1.items()}\n",
    "test_dicts_bb2_reverse = {val:key for key, val in test_dicts_bb2.items()}\n",
    "test_dicts_bb3_reverse = {val:key for key, val in test_dicts_bb3.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb1_smiles_train = [smiles for smiles in train_dicts_bb1.values()]\n",
    "bb2_smiles_train = [smiles for smiles in train_dicts_bb2.values()]\n",
    "bb3_smiles_train = [smiles for smiles in train_dicts_bb3.values()]\n",
    "bb1_smiles_test = [smiles for smiles in test_dicts_bb1.values()]\n",
    "bb2_smiles_test = [smiles for smiles in test_dicts_bb2.values()]\n",
    "bb3_smiles_test = [smiles for smiles in test_dicts_bb3.values()]\n",
    "\n",
    "bb1_mols_train = [Chem.MolFromSmiles(smiles) for smiles in bb1_smiles_train]\n",
    "bb2_mols_train = [Chem.MolFromSmiles(smiles) for smiles in bb2_smiles_train]\n",
    "bb3_mols_train = [Chem.MolFromSmiles(smiles) for smiles in bb3_smiles_train]\n",
    "bb1_mols_test = [Chem.MolFromSmiles(smiles) for smiles in bb1_smiles_test]\n",
    "bb2_mols_test = [Chem.MolFromSmiles(smiles) for smiles in bb2_smiles_test]\n",
    "bb3_mols_test = [Chem.MolFromSmiles(smiles) for smiles in bb3_smiles_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTデータ shared or nonshared, triazine有無で分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>buildingblock1_smiles</th>\n",
       "      <th>buildingblock2_smiles</th>\n",
       "      <th>buildingblock3_smiles</th>\n",
       "      <th>molecule_smiles</th>\n",
       "      <th>protein_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>295246830</td>\n",
       "      <td>C#CCCC[C@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O</td>\n",
       "      <td>C=Cc1ccc(N)cc1</td>\n",
       "      <td>C=Cc1ccc(N)cc1</td>\n",
       "      <td>C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2ccc(C=C...</td>\n",
       "      <td>BRD4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>295246831</td>\n",
       "      <td>C#CCCC[C@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O</td>\n",
       "      <td>C=Cc1ccc(N)cc1</td>\n",
       "      <td>C=Cc1ccc(N)cc1</td>\n",
       "      <td>C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2ccc(C=C...</td>\n",
       "      <td>HSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>295246832</td>\n",
       "      <td>C#CCCC[C@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O</td>\n",
       "      <td>C=Cc1ccc(N)cc1</td>\n",
       "      <td>C=Cc1ccc(N)cc1</td>\n",
       "      <td>C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2ccc(C=C...</td>\n",
       "      <td>sEH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                            buildingblock1_smiles  \\\n",
       "0  295246830  C#CCCC[C@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O   \n",
       "1  295246831  C#CCCC[C@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O   \n",
       "2  295246832  C#CCCC[C@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O   \n",
       "\n",
       "  buildingblock2_smiles buildingblock3_smiles  \\\n",
       "0        C=Cc1ccc(N)cc1        C=Cc1ccc(N)cc1   \n",
       "1        C=Cc1ccc(N)cc1        C=Cc1ccc(N)cc1   \n",
       "2        C=Cc1ccc(N)cc1        C=Cc1ccc(N)cc1   \n",
       "\n",
       "                                     molecule_smiles protein_name  \n",
       "0  C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2ccc(C=C...         BRD4  \n",
       "1  C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2ccc(C=C...          HSA  \n",
       "2  C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2ccc(C=C...          sEH  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_parquet(paths.DATA_DIR / 'test.parquet')\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['BB1shared'] = df_test[\"buildingblock1_smiles\"].isin(bb1_smiles_train)\n",
    "df_test['BB2shared'] = df_test[\"buildingblock2_smiles\"].isin(bb2_smiles_train)\n",
    "df_test['BB3shared'] = df_test[\"buildingblock3_smiles\"].isin(bb3_smiles_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1674896/1674896 [02:43<00:00, 10255.81it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "triazine = Chem.MolFromSmiles('C1=NC=NC=N1')\n",
    "def check_for_triazine(x):\n",
    "    check = Chem.MolFromSmiles(x).HasSubstructMatch(triazine)\n",
    "    return check\n",
    "\n",
    "df_test['triazine'] = df_test['molecule_smiles'].progress_apply(check_for_triazine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BB1shared</th>\n",
       "      <th>BB2shared</th>\n",
       "      <th>BB3shared</th>\n",
       "      <th>triazine</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>67779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1107117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BB1shared  BB2shared  BB3shared  triazine    count\n",
       "0      False      False      False     False   500000\n",
       "1      False      False      False      True    67779\n",
       "2       True       True       True      True  1107117"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combination_counts = df_test.groupby(['BB1shared', 'BB2shared', 'BB3shared', 'triazine']).size().reset_index(name='count')\n",
    "display(combination_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idを調べる\n",
    "shared_bb = df_test[(df_test['BB1shared']==True) & (df_test['BB2shared']==True) & (df_test['BB3shared']==True) & (df_test['triazine']==True)]\n",
    "non_shared_bb = df_test[(df_test['BB1shared']==False) & (df_test['BB2shared']==False) & (df_test['BB3shared']==False) & (df_test['triazine']==True)]\n",
    "new_liblary = df_test[(df_test['BB1shared']==False) & (df_test['BB2shared']==False) & (df_test['BB3shared']==False) & (df_test['triazine']==False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id_dict = {'new_library':new_liblary[\"id\"].values.tolist(),\n",
    " 'shared_bb':shared_bb[\"id\"].values.tolist(),\n",
    " 'non_shared_bb':non_shared_bb[\"id\"].values.tolist()}\n",
    "\n",
    "# save pickle\n",
    "with open(paths.MY_DATA_DIR / 'test_id_dict.p', 'wb') as file:\n",
    "    pickle.dump(test_id_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分子をscaffoldごとにクラスタリングする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 271/271 [00:00<00:00, 3605.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# bb1のscaffoldを取得\n",
    "scaffold_dict = {}\n",
    "for smiles in tqdm(bb1_smiles_train):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    scaffold = MurckoScaffold.GetScaffoldForMol(mol)\n",
    "    scaffold_smiles = Chem.MolToSmiles(scaffold)\n",
    "    \n",
    "    scaffold_dict[smiles] = scaffold_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ※ train dataの処理\n",
    "# scaffold → intの辞書を作成\n",
    "scaffold_list = list(set([s for s in scaffold_dict.values()]))\n",
    "scaffold_list.sort()\n",
    "\n",
    "scaffold_idx_dict = {s:num for num, s in enumerate(scaffold_list)}\n",
    "scaffold_idx_dict_reverse = {num:s for num, s in enumerate(scaffold_list)}\n",
    "\n",
    "# 保存\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'train_dicts/BBs_scaffold_dict_1.p', mode='wb') as f:\n",
    "  pickle.dump(scaffold_idx_dict, f)\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'train_dicts/BBs_scaffold_dict_reverse_1.p', mode='wb') as f:\n",
    "  pickle.dump(scaffold_idx_dict_reverse, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 63)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# タニモト係数に応じてグループ分け\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "\n",
    "scaffold_mols = [Chem.MolFromSmiles(s) for s in scaffold_list]\n",
    "morgan_fp = [AllChem.GetMorganFingerprintAsBitVect(x, 2, 2048) for x in scaffold_mols]\n",
    "\n",
    "dis_matrix = [DataStructs.BulkTanimotoSimilarity(morgan_fp[i], morgan_fp, returnDistance=True) for i in range(len(morgan_fp))]\n",
    "### numpy.ndarrayへの変換\n",
    "dis_array = np.array(dis_matrix)\n",
    "dis_array.shape ### (5000, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各クラスタのscaffold数\n",
      "3    19\n",
      "4    16\n",
      "0    15\n",
      "1    12\n",
      "2     1\n",
      "dtype: int64\n",
      "各クラスタのscaffold数(修正後)\n",
      "0 26\n",
      "1 1\n",
      "2 1\n",
      "3 19\n",
      "4 16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=5)\n",
    "kmeans.fit(dis_array)\n",
    "\n",
    "print('各クラスタのscaffold数')\n",
    "print(pd.value_counts(kmeans.labels_))\n",
    "\n",
    "fold_scaffold_dict = {i: [] for i in range(5)}\n",
    "for n,j in enumerate(kmeans.labels_):\n",
    "    fold_scaffold_dict[j].append(scaffold_list[n])\n",
    "    \n",
    "# fold1のscaffoldの4番目だけをfold0にして、それ以外ををfold0に押し込む（圧倒的に数が多いので）\n",
    "num = 4\n",
    "fold_scaffold_dict[0].extend(fold_scaffold_dict[1][:num] + fold_scaffold_dict[1][num+1:])\n",
    "fold_scaffold_dict[1] = [fold_scaffold_dict[1][num]]\n",
    "\n",
    "print('各クラスタのscaffold数(修正後)')\n",
    "for fold, s_list in fold_scaffold_dict.items():\n",
    "    print(fold, len(s_list))\n",
    "\n",
    "fold_scaffold_dict_reverse = {}\n",
    "# key, valの入れ替え\n",
    "for fold, s_list in fold_scaffold_dict.items():\n",
    "    for s in s_list:\n",
    "        fold_scaffold_dict_reverse[s] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    44307006\n",
       "0    36320979\n",
       "4    10163121\n",
       "2     7261161\n",
       "1      363343\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bb1_idx_to_fold(bb1_idx):\n",
    "    bb1_smiles = train_dicts_bb1[bb1_idx]\n",
    "    bb1_scaffold_smi = scaffold_dict[bb1_smiles]\n",
    "    fold = fold_scaffold_dict_reverse[bb1_scaffold_smi]\n",
    "    return fold\n",
    "\n",
    "# 辞書にする\n",
    "bb1idx2fold = {bb1_idx:bb1_idx_to_fold(bb1_idx) for bb1_idx in df_train['buildingblock1_smiles'].unique()}\n",
    "\n",
    "df_train['fold'] = df_train['buildingblock1_smiles'].map(bb1idx2fold)\n",
    "df_train['fold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold0\n",
      "binds_BRD4    0.006064\n",
      "binds_HSA     0.004038\n",
      "binds_sEH     0.002274\n",
      "dtype: float64\n",
      "---\n",
      "fold1\n",
      "binds_BRD4    0.003272\n",
      "binds_HSA     0.004994\n",
      "binds_sEH     0.002603\n",
      "dtype: float64\n",
      "---\n",
      "fold2\n",
      "binds_BRD4    0.004564\n",
      "binds_HSA     0.002907\n",
      "binds_sEH     0.044195\n",
      "dtype: float64\n",
      "---\n",
      "fold3\n",
      "binds_BRD4    0.002707\n",
      "binds_HSA     0.003055\n",
      "binds_sEH     0.001804\n",
      "dtype: float64\n",
      "---\n",
      "fold4\n",
      "binds_BRD4    0.005811\n",
      "binds_HSA     0.004069\n",
      "binds_sEH     0.004720\n",
      "dtype: float64\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# >>> fold2のbinds_sEHだけ以上に多い\n",
    "for fold in range(5):\n",
    "    print(f'fold{fold}')\n",
    "    print(df_train[df_train['fold'] == fold][TARGETS].mean())\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scaffold idx を df に足しておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb1_idx_to_scaffold_idx(bb1_idx):\n",
    "    bb1_smiles = train_dicts_bb1[bb1_idx]\n",
    "    bb1_scaffold_smi = scaffold_dict[bb1_smiles]\n",
    "    scaffold_idx = scaffold_idx_dict[bb1_scaffold_smi]\n",
    "    return scaffold_idx\n",
    "\n",
    "# 辞書にする（bb1_idx → scaffold_idx）\n",
    "bb1idx2scaidx = {bb1_idx:bb1_idx_to_scaffold_idx(bb1_idx) for bb1_idx in df_train['buildingblock1_smiles'].unique()}\n",
    "\n",
    "df_train['bb1_scaffold_idx'] = df_train['buildingblock1_smiles'].map(bb1idx2scaidx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:00<00:00, 6190.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# bb1のscaffoldを取得\n",
    "scaffold_dict = {}\n",
    "for smiles in tqdm(bb1_smiles_test):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    scaffold = MurckoScaffold.GetScaffoldForMol(mol)\n",
    "    scaffold_smiles = Chem.MolToSmiles(scaffold)\n",
    "    \n",
    "    scaffold_dict[smiles] = scaffold_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaffold → intの辞書を作成\n",
    "scaffold_list = list(set([s for s in scaffold_dict.values()]))\n",
    "scaffold_list.sort()\n",
    "\n",
    "scaffold_idx_dict = {s:num for num, s in enumerate(scaffold_list)}\n",
    "scaffold_idx_dict_reverse = {num:s for num, s in enumerate(scaffold_list)}\n",
    "\n",
    "# 保存\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'test_dicts/BBs_scaffold_dict_1.p', mode='wb') as f:\n",
    "  pickle.dump(scaffold_idx_dict, f)\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'test_dicts/BBs_scaffold_dict_reverse_1.p', mode='wb') as f:\n",
    "  pickle.dump(scaffold_idx_dict_reverse, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb1_idx_to_scaffold_idx(bb1_idx):\n",
    "    bb1_smiles = test_dicts_bb1[bb1_idx]\n",
    "    bb1_scaffold_smi = scaffold_dict[bb1_smiles]\n",
    "    scaffold_idx = scaffold_idx_dict[bb1_scaffold_smi]\n",
    "    return scaffold_idx\n",
    "\n",
    "# 辞書にする（bb1_idx → scaffold_idx）\n",
    "bb1idx2scaidx = {bb1_idx:bb1_idx_to_scaffold_idx(bb1_idx) for bb1_idx in df_test['buildingblock1_smiles'].unique()}\n",
    "df_test['bb1_scaffold_idx'] = df_test['buildingblock1_smiles'].map(bb1idx2scaidx)\n",
    "\n",
    "# コード実行時に必要になるので辞書も保存しておく\n",
    "with open(paths.SHRUNKEN_DATA_DIR / 'test_dicts/BBs_idx_to_scaffold_idx_dict_1.p', mode='wb') as f:\n",
    "  pickle.dump(bb1idx2scaidx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 保存\n",
    "df_train.to_parquet(paths.SHRUNKEN_DATA_DIR / 'train_fold.parquet')\n",
    "df_test.to_parquet(paths.SHRUNKEN_DATA_DIR / 'test_fold.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
